{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import AutoConfig\n",
    "config = AutoConfig(search_path='./../.env')\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = config('AZURE_API_KEY')\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = config('AZURE_ENDPOINT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanila Large Language Models (LLMs)\n",
    "\n",
    "LLMs are primarily designed for generating contextually relevant text, with primary focus on generating, completing, and language understanding. These models are pre-trained on diverse corpus capturing linguistic patterns for language understanding. They are widely used for downstream tasks like translation, summarization, task/domain-specific fine-tuning. etc.\n",
    "\n",
    "Some prominent examples:\n",
    "- GPT-3\n",
    "- llama, llama-2, llama-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI Model (Azure endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAI\n",
    "\n",
    "temp = 0.3\n",
    "max_tokens = 1024\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"text-davinci-003\",\n",
    "    model_name=\"text-davinci-003\",\n",
    "    api_version = \"2022-12-01\",\n",
    "    temperature=temp,\n",
    "    max_tokens=max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Living with purpose, love, and joy.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"What is the meaning of life in 10 words?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat or Instruction tuned Models\n",
    "\n",
    "Chat or instruction models are specifically designed for following user instructions or engaging in conversation with the user. They are LLMs that are further fine-tuned with specific datasets. Their main focus is to understand the context from user queries and respond accordingly. They are widely used for question answering, chatbots, dialogoe systems, etc.\n",
    "\n",
    "Some prominent examples:\n",
    "- GPT-3.5-turbo, GPT-4\n",
    "- llama-chat models\n",
    "- claude-2\n",
    "\n",
    "In langchain, a chat model is a language model that uses chat messages as inputs and returns chat messages as outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Passing user message to model through HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "message = [HumanMessage(\"What is the meaning of life in 10 words?\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI models (Azure endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    azure_deployment=\"gpt-35-turbo\",\n",
    "    temperature=temp,\n",
    "    max_tokens=max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`invoke()` call the chain on an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='To love, learn, grow, connect, create, and find purpose.'\n"
     ]
    }
   ],
   "source": [
    "print(chat_llm.invoke(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stream()` stream back chunks of the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To love, learn, grow, connect, create, and find purpose."
     ]
    }
   ],
   "source": [
    "for chunk in chat_llm.stream(message):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm_gpt4 = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    azure_deployment=\"gpt-4\",\n",
    "    temperature=temp,\n",
    "    max_tokens=max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Discover purpose, cultivate love, pursue growth, embrace experiences, seek happiness.'\n"
     ]
    }
   ],
   "source": [
    "print(chat_llm_gpt4.invoke(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S.: The LLM returns a string, while the ChatModel returns a message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts and Prompt Templates\n",
    "\n",
    "A **prompt** could be an instruction or a query that is passed to the llm. At times, it can also contain some more details in the form of context, input, or example.\n",
    "\n",
    "A **prompt template** is a wrapper around user-prompt providing extra layer of information specific to model and task. With prompt template user input can become more dynamic, as it can provide a placeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate\n",
    "\n",
    "`PromptTemplate` is used to create a template for a string prompt.\n",
    "\n",
    "Important Functions:\n",
    "- `PromptTemplate.from_template()` defines the template\n",
    "- `PromptTemplate.format()` to format the defined template with user input.\n",
    "\n",
    "Reference: [langchain PromptTemplate](https://python.langchain.com/docs/modules/model_io/prompts/quick_start/#prompttemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the meaning of life in less than 100 words ?\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is the meaning of life in less than {num_of_words} words {style}?\")\n",
    "print(prompt.format(num_of_words=100, style=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['num_of_words', 'style'], template='What is the meaning of life in less than {num_of_words} words {style}?')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Living with purpose and joy.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(prompt.format(num_of_words=10, style=\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The meaning of life is to find joy and purpose in the journey of life and to make a positive impact on the world.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(prompt.format(num_of_words=50, style=\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Life is a great big roller coaster ride, so buckle up and enjoy the ups and downs!\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(prompt.format(num_of_words=50, style=\"in a funny way\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "\n",
    "`ChatPromptTemplate`, prompt template for chat models, is a list of `ChatMessageTemplates`. Each `ChatMessageTemplate` contains instructions for how to format that `ChatMessage` - its role, and then also its content.\n",
    "\n",
    "Important Functions:\n",
    "- `ChatPromptTemplate.from_messages()` defines the chat template\n",
    "- `ChatPromptTemplate.format_messages()` to format the defined template with user input.\n",
    "\n",
    "Reference: \n",
    "- [langchain ChatPromptTemplate](https://python.langchain.com/docs/modules/model_io/prompts/quick_start/#chatprompttemplate)\n",
    "- [OpenAI ChatCOmpletion](https://platform.openai.com/docs/guides/text-generation/chat-completions-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is the meaning of life in less than {num_of_words} words {style}?\")\n",
    "message = prompt.format(num_of_words=50, style=\"in a funny way\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is the meaning of life in less than 50 words in a funny way?\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(message)\n",
    "print(type(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chat_message = chat_prompt.format_messages(input_language=\"English\", \n",
    "                            output_language=\"Hindi\", \n",
    "                            text=\"The meaning of life is to find joy and purpose in living, and to make a positive impact on the world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Hindi.'), HumanMessage(content='The meaning of life is to find joy and purpose in living, and to make a positive impact on the world.')]\n",
      "<class 'list'>\n",
      "content='You are a helpful assistant that translates English to Hindi.'\n",
      "content='The meaning of life is to find joy and purpose in living, and to make a positive impact on the world.'\n"
     ]
    }
   ],
   "source": [
    "print(chat_message)\n",
    "print(type(chat_message))\n",
    "for msg in chat_message:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='जीवन का अर्थ जीवन में आनंद और उद्देश्य खोजना है, और दुनिया पर सकारात्मक प्रभाव डालना है।'\n"
     ]
    }
   ],
   "source": [
    "print(chat_llm.invoke(chat_prompt.format_messages(input_language=\"English\", \n",
    "                            output_language=\"Hindi\", \n",
    "                            text=\"The meaning of life is to find joy and purpose in living, and to make a positive impact on the world.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=PromptTemplate(input_variables=['word_count'], template='Summarise the converstion in {word_count} words.')\n",
      "input_variables=['conversation', 'word_count'] input_types={'conversation': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], template='Summarise the converstion in {word_count} words.')), MessagesPlaceholder(variable_name='conversation')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "\n",
    "human_template = \"Summarise the converstion in {word_count} words.\"\n",
    "humman_message_template = HumanMessagePromptTemplate.from_template(human_template)\n",
    "print(humman_message_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [humman_message_template, MessagesPlaceholder(variable_name=\"conversation\")]\n",
    ")\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Summarise the converstion in 20 words.'), HumanMessage(content='What is the meaning of life in less than 20 words?'), AIMessage(content='The meaning of life is to find joy and purpose in living, and to make a positive impact on the world.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "human_message = HumanMessage(content=\"What is the meaning of life in less than 20 words?\")\n",
    "ai_message = AIMessage(\n",
    "    content=\"\"\"The meaning of life is to find joy and purpose in living, and to make a positive impact on the world.\"\"\"\n",
    ")\n",
    "\n",
    "chat_message = chat_prompt.format_prompt(\n",
    "    conversation=[human_message, ai_message], word_count=20,\n",
    ")\n",
    "print(chat_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Exploring purpose, finding joy, making a positive impact, and experiencing personal growth throughout life's journey.\"\n"
     ]
    }
   ],
   "source": [
    "print(chat_llm_gpt4.invoke(chat_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more examples, reference [langchain docs](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html), [langchain tutorials](https://python.langchain.com/docs/modules/model_io/prompts/quick_start/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parser\n",
    "\n",
    "`OutputParsers` convert the raw output of a language model into a format that can be used downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\"thought\": \"The meaning of life is subjective and varies from person to person.\"}'\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    thought: str = Field(description=\"answer with thought.\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Answer)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query in less than {word_count} words.\\n\\n{format_instructions}\\n\\n{query}\\n\",\n",
    "    input_variables=[\"word_count\", \"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "response = chat_llm.invoke(prompt.format(word_count=20, query=\"What is the meaning of life?\"))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought='The meaning of life is subjective and varies from person to person.'\n"
     ]
    }
   ],
   "source": [
    "print(parser.invoke(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is subjective and varies from person to person.\n"
     ]
    }
   ],
   "source": [
    "print(parser.invoke(response).thought)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-In Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### JSONOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\\n  \"Question\": \"What is the meaning of life?\",\\n  \"Answer\": \"The meaning of life is subjective and varies from person to person.\"\\n}'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"Return the response in JSON format with keys Question and Answer by answering the user query in less than {word_count} words.\\n\\n{format_instructions}\\n\\n{query}\\n\"\"\",\n",
    "    input_variables=[\"word_count\", \"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "response = chat_llm.invoke(prompt.format(word_count=20, query=\"What is the meaning of life?\"))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'Question': 'What is the meaning of life?', 'Answer': 'The meaning of life is subjective and varies from person to person.'}\n"
     ]
    }
   ],
   "source": [
    "print(type(parser.invoke(response)))\n",
    "print(parser.invoke(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the meaning of life?\n"
     ]
    }
   ],
   "source": [
    "print(parser.invoke(response)['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is subjective and varies from person to person.\n"
     ]
    }
   ],
   "source": [
    "print(parser.invoke(response)['Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
