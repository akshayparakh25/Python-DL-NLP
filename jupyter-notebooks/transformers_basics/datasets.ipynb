{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c28a7cf-8431-45c6-a1e2-81fc058cfa83",
   "metadata": {},
   "source": [
    "# Exploing `datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f30441e-f767-498d-8b85-47f7f49ed7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cddece1-e6e4-4d3c-8bd2-386073888596",
   "metadata": {},
   "source": [
    "### Loading a local dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40854b5c-d89e-46c1-b11a-aecad741bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_dataset = load_dataset(\"csv\", data_files=\"./../../data/FiQA_and_Financial_PhraseBank_in_1/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3da30c-8b23-4762-9029-ecd7b36d303e",
   "metadata": {},
   "source": [
    "|Data format       |Loading script| \tExample                                              |\n",
    "|------------------|:------------:|---------------------------------------------------------:|\n",
    "|CSV & TSV         |csv           | \tload_dataset(\"csv\", data_files=\"my_file.csv\")        |\n",
    "|Text files        |text          | \tload_dataset(\"text\", data_files=\"my_file.txt\")       |\n",
    "|JSON & JSON Lines |json          | \tload_dataset(\"json\", data_files=\"my_file.jsonl\")     |\n",
    "|Pickled DataFrames|pandas        | \tload_dataset(\"pandas\", data_files=\"my_dataframe.pkl\")|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb5f8b5-d05c-4729-80ad-e686aad7c7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Sentence', 'Sentiment'],\n",
       "        num_rows: 5842\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d75e7e-af8e-4596-b1ca-d333e499dbc1",
   "metadata": {},
   "source": [
    "This creates `DatasetDict` object with a train split. If there are multiple files such as train, dev, and test, the `data_files` argument of the `load_dataset()` function is quite flexible and can be either a single file path, a list of file paths, or a dictionary that maps split names to file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc172c1-311b-4188-b1ae-7c670b2ba3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['relation', 'stanford_deprel', 'subj_start', 'stanford_ner', 'obj_start', 'token', 'stanford_head', 'subj_type', 'subj_end', 'stanford_pos', 'obj_type', 'docid', 'obj_end', 'id'],\n",
       "        num_rows: 58465\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['relation', 'stanford_deprel', 'subj_start', 'stanford_ner', 'obj_start', 'token', 'stanford_head', 'subj_type', 'subj_end', 'stanford_pos', 'obj_type', 'docid', 'obj_end', 'id'],\n",
       "        num_rows: 19584\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['relation', 'stanford_deprel', 'subj_start', 'stanford_ner', 'obj_start', 'token', 'stanford_head', 'subj_type', 'subj_end', 'stanford_pos', 'obj_type', 'docid', 'obj_end', 'id'],\n",
       "        num_rows: 13418\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {'train':'./../../data/re-tacred/train.json', \n",
    "              'dev':'./../../data/re-tacred/dev.json', \n",
    "              'test':'./../../data/re-tacred/test.json'}\n",
    "\n",
    "re_dataset = load_dataset(\"json\", data_files=data_files)\n",
    "re_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95439e-e634-4ec4-bc29-ff6f9f0f8ebe",
   "metadata": {},
   "source": [
    "**NOTE:** `load_dataset() fucntion can also perform automatic decompression to common formats like ZIP and TAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61f423-681c-44b5-b842-e2d5d5f7941a",
   "metadata": {},
   "source": [
    "## Dataset Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55013ef8-b653-4616-8dad-0046e4aec324",
   "metadata": {},
   "source": [
    "##### Selecting a random sample for data analysis.\n",
    "\n",
    "`Dataset.select()` expects an iterable of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57590779-c5d9-471e-a613-40e7108922ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sc_dataset[\"train\"].shuffle(seed=25).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80cc97a-4682-4c7b-af8b-ef55ff1175c7",
   "metadata": {},
   "source": [
    "### Dataset Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6599478c-8cc4-437c-b733-1cf59f9e4db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentence': \"Mr Kivimeister said John Deer former Timberjack stands to win in the situation : it controls around 60 % of Estonia 's forest machinery market .\",\n",
       " 'Sentiment': 'positive'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad1eea1-68f5-4bee-84d3-5824abd9360f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentence': [\"Mr Kivimeister said John Deer former Timberjack stands to win in the situation : it controls around 60 % of Estonia 's forest machinery market .\",\n",
       "  'The tightened competition situation in the production automation market has affected net sales during 2006 , Cencorp said .',\n",
       "  '1 p.m. Central office of Nordea Bank 19 3-ya ulitsa Yamskogo Polya , Building 1 Telephone : 495 777-34-77 ext. 3932 , 3931 03.02.2011 Unimilk - EGM 03-04 .02.2011 XVI international business-summit Food Business Russia 2011 will take place .',\n",
       "  \"Before Kemira 's installation NordAlu was producing 3,500 tons of liquid and solid aluminum waste per year .\"],\n",
       " 'Sentiment': ['positive', 'neutral', 'neutral', 'neutral']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf7e26-cb44-44db-8ddd-3e0ac9a369cc",
   "metadata": {},
   "source": [
    "### Important functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d993d71-3f6a-4111-81b2-5958b3681fe2",
   "metadata": {},
   "source": [
    "##### unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce72e9c-6e3a-40b1-9b37-9f3c8ed15af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'neutral', 'negative']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.unique('Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68e5cf7-3b9b-4ab9-8855-7f06f23c01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in re_dataset.keys():\n",
    "    assert len(re_dataset[split].unique('id')) == len(re_dataset[split])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949749b2-f180-4008-804c-7ee02787ee32",
   "metadata": {},
   "source": [
    "##### filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4d81d4-67ac-4463-aafe-cf339b4973ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981\n"
     ]
    }
   ],
   "source": [
    "# Filtering samples with sentence length greater than 5\n",
    "sample = sample.filter(lambda x: len(x[\"Sentence\"].split()) > 5)\n",
    "print(len(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d3b64-9645-44e0-9416-444b900fa4e4",
   "metadata": {},
   "source": [
    "##### map()\n",
    "\n",
    "The `map()` function supports processing batches of examples at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3d1d1a-f4b5-41ed-871e-1ab9bdfa39ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relation': 'org:founded_by',\n",
       " 'stanford_deprel': ['compound',\n",
       "  'nsubj',\n",
       "  'ROOT',\n",
       "  'case',\n",
       "  'nmod',\n",
       "  'amod',\n",
       "  'nmod:tmod',\n",
       "  'mark',\n",
       "  'xcomp',\n",
       "  'det',\n",
       "  'compound',\n",
       "  'compound',\n",
       "  'dobj',\n",
       "  'punct',\n",
       "  'appos',\n",
       "  'punct',\n",
       "  'punct',\n",
       "  'xcomp',\n",
       "  'det',\n",
       "  'dobj',\n",
       "  'case',\n",
       "  'nummod',\n",
       "  'nmod',\n",
       "  'case',\n",
       "  'nmod',\n",
       "  'punct',\n",
       "  'xcomp',\n",
       "  'amod',\n",
       "  'compound',\n",
       "  'compound',\n",
       "  'compound',\n",
       "  'dobj',\n",
       "  'mark',\n",
       "  'xcomp',\n",
       "  'dobj',\n",
       "  'cc',\n",
       "  'conj',\n",
       "  'det',\n",
       "  'compound',\n",
       "  'dobj',\n",
       "  'punct'],\n",
       " 'subj_start': 10,\n",
       " 'stanford_ner': ['PERSON',\n",
       "  'PERSON',\n",
       "  'O',\n",
       "  'O',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'ORGANIZATION',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'NUMBER',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'PERSON',\n",
       "  'PERSON',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " 'obj_start': 0,\n",
       " 'token': ['Tom',\n",
       "  'Thabane',\n",
       "  'resigned',\n",
       "  'in',\n",
       "  'October',\n",
       "  'last',\n",
       "  'year',\n",
       "  'to',\n",
       "  'form',\n",
       "  'the',\n",
       "  'All',\n",
       "  'Basotho',\n",
       "  'Convention',\n",
       "  '-LRB-',\n",
       "  'ABC',\n",
       "  '-RRB-',\n",
       "  ',',\n",
       "  'crossing',\n",
       "  'the',\n",
       "  'floor',\n",
       "  'with',\n",
       "  '17',\n",
       "  'members',\n",
       "  'of',\n",
       "  'parliament',\n",
       "  ',',\n",
       "  'causing',\n",
       "  'constitutional',\n",
       "  'monarch',\n",
       "  'King',\n",
       "  'Letsie',\n",
       "  'III',\n",
       "  'to',\n",
       "  'dissolve',\n",
       "  'parliament',\n",
       "  'and',\n",
       "  'call',\n",
       "  'the',\n",
       "  'snap',\n",
       "  'election',\n",
       "  '.'],\n",
       " 'stanford_head': [2,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  9,\n",
       "  15,\n",
       "  13,\n",
       "  15,\n",
       "  3,\n",
       "  3,\n",
       "  20,\n",
       "  18,\n",
       "  23,\n",
       "  23,\n",
       "  18,\n",
       "  25,\n",
       "  23,\n",
       "  3,\n",
       "  3,\n",
       "  32,\n",
       "  32,\n",
       "  32,\n",
       "  32,\n",
       "  27,\n",
       "  34,\n",
       "  27,\n",
       "  34,\n",
       "  34,\n",
       "  34,\n",
       "  40,\n",
       "  40,\n",
       "  37,\n",
       "  3],\n",
       " 'subj_type': 'ORGANIZATION',\n",
       " 'subj_end': 12,\n",
       " 'stanford_pos': ['NNP',\n",
       "  'NNP',\n",
       "  'VBD',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'TO',\n",
       "  'VB',\n",
       "  'DT',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  '-LRB-',\n",
       "  'NNP',\n",
       "  '-RRB-',\n",
       "  ',',\n",
       "  'VBG',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'CD',\n",
       "  'NNS',\n",
       "  'IN',\n",
       "  'NN',\n",
       "  ',',\n",
       "  'VBG',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'TO',\n",
       "  'VB',\n",
       "  'NN',\n",
       "  'CC',\n",
       "  'VB',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'NN',\n",
       "  '.'],\n",
       " 'obj_type': 'PERSON',\n",
       " 'docid': 'AFP_ENG_20070218.0019.LDC2009T13',\n",
       " 'obj_end': 1,\n",
       " 'id': '61b3a5c8c9a882dcfcd2',\n",
       " 'sentence': 'Tom Thabane resigned in October last year to form the All Basotho Convention -LRB- ABC -RRB- , crossing the floor with 17 members of parliament , causing constitutional monarch King Letsie III to dissolve parliament and call the snap election .'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_sentences(examples):\n",
    "    return {'sentence': ' '.join(examples[\"token\"])}\n",
    "\n",
    "re_dataset = re_dataset.map(add_sentences)\n",
    "re_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e28c745-b2d2-4c0e-96d8-67fa828da2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./../../../hf_models/distilbert-base-uncased/\")\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccaa3793-8b1e-41c4-a75c-ea1531bfbaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 131 ms, sys: 7.8 ms, total: 139 ms\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_dataset = re_dataset.map(tokenize, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce5a8d-d2c6-427f-bb04-84d5805d3a67",
   "metadata": {},
   "source": [
    "**Parallelization** can be achieved using the parameter `batched=True`, thus making the process fast. For large datasets, multiprocessing can be enabled using the parameter `num_proc` to specify the number of processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1caa82e1-c86e-40f1-bb99-0a3e8a498e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relation': 'org:founded_by',\n",
       " 'stanford_deprel': ['compound',\n",
       "  'nsubj',\n",
       "  'ROOT',\n",
       "  'case',\n",
       "  'nmod',\n",
       "  'amod',\n",
       "  'nmod:tmod',\n",
       "  'mark',\n",
       "  'xcomp',\n",
       "  'det',\n",
       "  'compound',\n",
       "  'compound',\n",
       "  'dobj',\n",
       "  'punct',\n",
       "  'appos',\n",
       "  'punct',\n",
       "  'punct',\n",
       "  'xcomp',\n",
       "  'det',\n",
       "  'dobj',\n",
       "  'case',\n",
       "  'nummod',\n",
       "  'nmod',\n",
       "  'case',\n",
       "  'nmod',\n",
       "  'punct',\n",
       "  'xcomp',\n",
       "  'amod',\n",
       "  'compound',\n",
       "  'compound',\n",
       "  'compound',\n",
       "  'dobj',\n",
       "  'mark',\n",
       "  'xcomp',\n",
       "  'dobj',\n",
       "  'cc',\n",
       "  'conj',\n",
       "  'det',\n",
       "  'compound',\n",
       "  'dobj',\n",
       "  'punct'],\n",
       " 'subj_start': 10,\n",
       " 'stanford_ner': ['PERSON',\n",
       "  'PERSON',\n",
       "  'O',\n",
       "  'O',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'ORGANIZATION',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'NUMBER',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'PERSON',\n",
       "  'PERSON',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " 'obj_start': 0,\n",
       " 'token': ['Tom',\n",
       "  'Thabane',\n",
       "  'resigned',\n",
       "  'in',\n",
       "  'October',\n",
       "  'last',\n",
       "  'year',\n",
       "  'to',\n",
       "  'form',\n",
       "  'the',\n",
       "  'All',\n",
       "  'Basotho',\n",
       "  'Convention',\n",
       "  '-LRB-',\n",
       "  'ABC',\n",
       "  '-RRB-',\n",
       "  ',',\n",
       "  'crossing',\n",
       "  'the',\n",
       "  'floor',\n",
       "  'with',\n",
       "  '17',\n",
       "  'members',\n",
       "  'of',\n",
       "  'parliament',\n",
       "  ',',\n",
       "  'causing',\n",
       "  'constitutional',\n",
       "  'monarch',\n",
       "  'King',\n",
       "  'Letsie',\n",
       "  'III',\n",
       "  'to',\n",
       "  'dissolve',\n",
       "  'parliament',\n",
       "  'and',\n",
       "  'call',\n",
       "  'the',\n",
       "  'snap',\n",
       "  'election',\n",
       "  '.'],\n",
       " 'stanford_head': [2,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  9,\n",
       "  15,\n",
       "  13,\n",
       "  15,\n",
       "  3,\n",
       "  3,\n",
       "  20,\n",
       "  18,\n",
       "  23,\n",
       "  23,\n",
       "  18,\n",
       "  25,\n",
       "  23,\n",
       "  3,\n",
       "  3,\n",
       "  32,\n",
       "  32,\n",
       "  32,\n",
       "  32,\n",
       "  27,\n",
       "  34,\n",
       "  27,\n",
       "  34,\n",
       "  34,\n",
       "  34,\n",
       "  40,\n",
       "  40,\n",
       "  37,\n",
       "  3],\n",
       " 'subj_type': 'ORGANIZATION',\n",
       " 'subj_end': 12,\n",
       " 'stanford_pos': ['NNP',\n",
       "  'NNP',\n",
       "  'VBD',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'TO',\n",
       "  'VB',\n",
       "  'DT',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  '-LRB-',\n",
       "  'NNP',\n",
       "  '-RRB-',\n",
       "  ',',\n",
       "  'VBG',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'CD',\n",
       "  'NNS',\n",
       "  'IN',\n",
       "  'NN',\n",
       "  ',',\n",
       "  'VBG',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'TO',\n",
       "  'VB',\n",
       "  'NN',\n",
       "  'CC',\n",
       "  'VB',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'NN',\n",
       "  '.'],\n",
       " 'obj_type': 'PERSON',\n",
       " 'docid': 'AFP_ENG_20070218.0019.LDC2009T13',\n",
       " 'obj_end': 1,\n",
       " 'id': '61b3a5c8c9a882dcfcd2',\n",
       " 'sentence': 'Tom Thabane resigned in October last year to form the All Basotho Convention -LRB- ABC -RRB- , crossing the floor with 17 members of parliament , causing constitutional monarch King Letsie III to dissolve parliament and call the snap election .',\n",
       " 'input_ids': [101,\n",
       "  3419,\n",
       "  22794,\n",
       "  27543,\n",
       "  5295,\n",
       "  1999,\n",
       "  2255,\n",
       "  2197,\n",
       "  2095,\n",
       "  2000,\n",
       "  2433,\n",
       "  1996,\n",
       "  2035,\n",
       "  19021,\n",
       "  29288,\n",
       "  4680,\n",
       "  1011,\n",
       "  1048,\n",
       "  15185,\n",
       "  1011,\n",
       "  5925,\n",
       "  1011,\n",
       "  25269,\n",
       "  2497,\n",
       "  1011,\n",
       "  1010,\n",
       "  5153,\n",
       "  1996,\n",
       "  2723,\n",
       "  2007,\n",
       "  2459,\n",
       "  2372,\n",
       "  1997,\n",
       "  3323,\n",
       "  1010,\n",
       "  4786,\n",
       "  6543,\n",
       "  11590,\n",
       "  2332,\n",
       "  11082,\n",
       "  2666,\n",
       "  3523,\n",
       "  2000,\n",
       "  21969,\n",
       "  3323,\n",
       "  1998,\n",
       "  2655,\n",
       "  1996,\n",
       "  10245,\n",
       "  2602,\n",
       "  1012,\n",
       "  102],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111695bb-34b5-4487-aaae-d1bce515e530",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96fb910d-6611-41e6-936d-a91040fd9168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Sentence', 'Sentiment'],\n",
       "        num_rows: 5842\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c81581e9-441d-45b0-9c41-cee85355f38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Sentence', 'Sentiment'],\n",
       "        num_rows: 5257\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Sentence', 'Sentiment'],\n",
       "        num_rows: 585\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_sc_dataset = sc_dataset[\"train\"].train_test_split(train_size=0.9, seed=25)\n",
    "splitted_sc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04ff9cde-2962-4c21-95c8-baca63cd6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Sentence', 'Sentiment'],\n",
       "        num_rows: 5257\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['Sentence', 'Sentiment'],\n",
       "        num_rows: 585\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_sc_dataset[\"dev\"] = splitted_sc_dataset.pop(\"test\")\n",
    "splitted_sc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "423f8a74-909e-4e69-8e56-ebef509d0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sc_dataset = splitted_sc_dataset[\"train\"].train_test_split(train_size=0.9, seed=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29e02f39-8d1b-4502-8418-5b9207a1a5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Sentence', 'Sentiment'],\n",
       "        num_rows: 4731\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Sentence', 'Sentiment'],\n",
       "        num_rows: 526\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['Sentence', 'Sentiment'],\n",
       "        num_rows: 585\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sc_dataset[\"dev\"] = splitted_sc_dataset[\"dev\"]\n",
    "final_sc_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c250034b-6e26-48ed-be20-ea66431ba573",
   "metadata": {},
   "source": [
    "## Saving the dataset\n",
    "\n",
    "The dault format is *Arrow*. Using default function `save_to_disk()`, the dataset will be saved in *Arrow*, where each split is associated with its own *dataset.arrow* table, and some metadata in *dataset_info.json* and *state.json*. \n",
    "\n",
    "|Data format| \tFunction|\n",
    "|-----------|-----------|\n",
    "|Arrow| \tDataset.save_to_disk()|\n",
    "|CSV| \tDataset.to_csv()|\n",
    "|JSON| \tDataset.to_json()|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a081e0-8c8b-45f9-9581-f8ace4210083",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, dataset in final_sc_dataset.items():\n",
    "    dat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
